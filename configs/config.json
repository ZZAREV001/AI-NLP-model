{
  "model_type": "transformer",
  "embed_size": 128,
  "n_layers": 6,
  "n_heads": 8,
  "dim": 512,
  "attention_dim": 64,
  "attention_heads": 8,
  "feed_forward_size": 2048,
  "dim_ff": 2048,
  "max_len": 512,
  "position_encoding": "sine",
  "src_vocab": 40000,
  "trg_vocab": 40000,
  "rl_agent": 5,
  "policy_layers": [128, 64],
  "value_layers": [128, 64],
  "epochs": 100,
  "learning_rate": 0.001
}
